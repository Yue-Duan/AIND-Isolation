This script evaluates the performance of the custom_score evaluation
function against a baseline agent using alpha-beta search and iterative
deepening (ID) called `AB_Improved`. The three `AB_Custom` agents use
ID and alpha-beta search with the custom_score functions defined in
game_agent.py.

                        *************************
                             Playing Matches
                        *************************

 Match #   Opponent    AB_Improved   AB_Custom   AB_Custom_2  AB_Custom_3
                        Won | Lost   Won | Lost   Won | Lost   Won | Lost
    1       Random      10  |   0    10  |   0     9  |   1    10  |   0
    2       MM_Open      5  |   5     8  |   2     6  |   4    10  |   0
    3      MM_Center     7  |   3     8  |   2    10  |   0     9  |   1
    4     MM_Improved    7  |   3     9  |   1     5  |   5     7  |   3
    5       AB_Open      6  |   4     2  |   8     8  |   2     6  |   4
    6      AB_Center     4  |   6     6  |   4     9  |   1     5  |   5
    7     AB_Improved    5  |   5     6  |   4     4  |   6     6  |   4
--------------------------------------------------------------------------
           Win Rate:      62.9%        70.0%        72.9%        75.7%

There were 6.0 timeouts during the tournament -- make sure your agent handles search timeout correctly, and consider increasing the timeout margin for your agent.
